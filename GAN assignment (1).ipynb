{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0473348-b4ee-4dfd-9726-2e6b5b4f7bef",
   "metadata": {},
   "source": [
    "## 1.Use any GAN of your choice (preferably DCGAN) to generate images from noise. Perform the following experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ee90e1-9285-466d-a894-a88afc232d3f",
   "metadata": {},
   "source": [
    "### A. Use the CIFAR 10 database to learn the GAN network. Generate images once the learning is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4939283-1f70-4fa7-910b-d176eb0b4a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the generator and discriminator networks\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, ngf, nc):\n",
    "        super(Generator, self).__init()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc, ndf):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# Set hyperparameters\n",
    "nz = 100  # Size of the input noise vector\n",
    "ngf = 64  # Number of generator filters\n",
    "ndf = 64  # Number of discriminator filters\n",
    "nc = 3    # Number of channels (RGB)\n",
    "lr = 0.0002\n",
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the generator and discriminator\n",
    "generator = Generator(nz, ngf, nc)\n",
    "discriminator = Discriminator(nc, ndf)\n",
    "\n",
    "# Initialize weights\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "# Define loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = datasets.CIFAR10(root='./data', download=True, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        real_images, _ = data\n",
    "        batch_size = real_images.size(0)\n",
    "        \n",
    "        # Update the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        real_labels = torch.full((batch_size,), 1.0)\n",
    "        fake_labels = torch.full((batch_size,), 0.0)\n",
    "        noise = torch.randn(batch_size, nz, 1, 1)\n",
    "        \n",
    "        # Generate fake images\n",
    "        fake_images = generator(noise)\n",
    "        \n",
    "        # Discriminator's loss for real and fake images\n",
    "        output_real = discriminator(real_images)\n",
    "        output_fake = discriminator(fake_images.detach())\n",
    "        \n",
    "        loss_real = criterion(output_real, real_labels)\n",
    "        loss_fake = criterion(output_fake, fake_labels)\n",
    "        loss_d = loss_real + loss_fake\n",
    "        \n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # Update the generator\n",
    "        generator.zero_grad()\n",
    "        output_fake = discriminator(fake_images)\n",
    "        loss_g = criterion(output_fake, real_labels)\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], Batch [{i}/{len(dataloader)}], Loss D: {loss_d.item()}, Loss G: {loss_g.\n",
    "                  item()}')\n",
    "\n",
    "# Generate and save some fake images\n",
    "noise = torch.randn(64, nz, 1, 1)\n",
    "fake_images = generator(noise)\n",
    "fake_images = fake_images.detach().numpy()\n",
    "\n",
    "# Display generated images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(64):\n",
    "    plt.subplot(8, 8, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(fake_images[i], (1, 2, 0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b97c376-78ec-4c1e-89fc-2b22232a7399",
   "metadata": {},
   "source": [
    "### B. Plot generator and discriminator losses and show how can you ascertain the convergence of the GAN training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2df300-f7c4-4fdf-b559-beb461f462ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Training a Generative Adversarial Network (GAN) involves monitoring the losses of both the generator and discriminator to \n",
    "assess the convergence of the training process. I'll provide a general outline of how to do this using DCGAN (Deep \n",
    "Convolutional GAN) as an example, but the specific implementation may vary depending on the framework you are using (e.g.,\n",
    "TensorFlow, PyTorch).\n",
    "\n",
    "Here's a step-by-step guide to plot the generator and discriminator losses and ascertain the convergence of the GAN training\n",
    "process:\n",
    "\n",
    "1.Initialize the GAN: Set up the generator and discriminator networks, along with their respective optimizers. Ensure that\n",
    "you have a well-defined architecture for both networks. In the case of DCGAN, convolutional layers are commonly used for \n",
    "better performance.\n",
    "\n",
    "2.Define Loss Functions:\n",
    "\n",
    "    ~Generator Loss: Typically, the generator minimizes the binary cross-entropy loss. The loss quantifies how well the \n",
    "    generator fools the discriminator.\n",
    "    ~Discriminator Loss: The discriminator minimizes the binary cross-entropy loss to distinguish between real and fake \n",
    "    images.\n",
    "    \n",
    "3.Training Loop:\n",
    "\n",
    "    ~In each iteration, generate a batch of random noise (randomly sampled from a normal distribution) and use the generator\n",
    "    to create fake images.\n",
    "    ~Combine these fake images with real images from your dataset.\n",
    "    ~Calculate the discriminator loss on the combined dataset.\n",
    "    ~Update the discriminator's weights using backpropagation and the discriminator optimizer.\n",
    "    ~Calculate the generator loss, which is based on the output of the discriminator when the fake images are passed through.\n",
    "    ~Update the generator's weights using backpropagation and the generator optimizer.\n",
    "    \n",
    "4.Log Losses:\n",
    "\n",
    "    ~During training, log the discriminator loss and generator loss at regular intervals (e.g., after each epoch or after\n",
    "     a certain number of batches).\n",
    "    \n",
    "5.Plot Losses:\n",
    "\n",
    "    ~Use a plotting library (e.g., Matplotlib) to create two separate plots for the discriminator loss and generator loss \n",
    "    over time.\n",
    "    \n",
    "6.Convergence Criteria:\n",
    "\n",
    "    ~Convergence of a GAN can be assessed by observing the loss curves. In general, you want to see the following:\n",
    "        ~The discriminator loss should decrease and stabilize as the discriminator becomes better at distinguishing real\n",
    "        from fake.\n",
    "        ~The generator loss should decrease and stabilize as the generator becomes better at producing realistic images.\n",
    "        ~The two loss curves should reach a balance, with neither the generator nor discriminator dominating. This \n",
    "        equilibrium indicates convergence.\n",
    "        \n",
    "7.Early Stopping (optional):\n",
    "\n",
    "    ~You can implement an early stopping mechanism based on your loss curves. If the losses do not show signs of convergence\n",
    "    (e.g., they keep fluctuating or diverging), you might want to stop training.\n",
    "    \n",
    "8.Visual Inspection:\n",
    "\n",
    "    ~Additionally, you can visually inspect the generated images over time to see if they improve in quality and realism.\n",
    "    \n",
    "The key to ensuring convergence is to carefully monitor the loss curves and experiment with different hyperparameters and \n",
    "network architectures until you achieve stable and realistic image generation.\n",
    "\n",
    "Remember that GAN training can be sensitive to hyperparameters like learning rates, architecture choices, and batch sizes.\n",
    "Experimenting with these parameters is often necessary to achieve good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2758dff3-959e-40c5-85df-d79a61f4946a",
   "metadata": {},
   "source": [
    "## 2.Fine-tuning Take a ResNet50 model and the database to be used for this question is CIFAR-10.Remove its classification layer and place a 2-layer neural network followed by a Softmax layer. Calculate classification accuracy on a train set, test set, and plot accuracies over epochs when:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa98bb-4825-4aa3-a461-be3f9eb02d99",
   "metadata": {},
   "source": [
    "### A. The complete network is trained from scratch (i.e, random weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca1c08-5a40-450a-b3db-46b670adc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Define the ResNet50 model without the top classification layer\n",
    "base_model = ResNet50(weights=None, include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Add custom classification layers\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the full model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model from scratch\n",
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_test, y_test))\n",
    "\n",
    "# Plot the training and validation accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate final classification accuracy on the train and test sets\n",
    "train_accuracy = model.evaluate(x_train, y_train, verbose=0)[1]\n",
    "test_accuracy = model.evaluate(x_test, y_test, verbose=0)[1]\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a124227b-579e-4d1e-a3b9-0c3d69b0fb67",
   "metadata": {},
   "source": [
    "### B. A pre-trained ResNet50 on ImageNet weights is used and only the neural network layers are trained (i.e, weights of layers of ResNet50 are kept frozen and unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1dfdb0-5914-4f8d-834c-24417f11ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, Softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Preprocess labels\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "# Load pre-trained ResNet50 with ImageNet weights\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=(32, 32, 3)))\n",
    "\n",
    "# Remove the original classification layer\n",
    "x = base_model.output\n",
    "\n",
    "# Add your custom layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)  # 10 classes in CIFAR-10\n",
    "\n",
    "# Create a new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the ResNet50 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Calculate and print the accuracy on the train and test sets\n",
    "train_accuracy = model.evaluate(train_images, train_labels, verbose=0)[1]\n",
    "test_accuracy = model.evaluate(test_images, test_labels, verbose=0)[1]\n",
    "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc255a-8860-4230-8004-badb5739b827",
   "metadata": {},
   "source": [
    "### C. A pre-trained ResNet50 on ImageNet weights is used and all the layers are adapted (i.e, weights of layers of ResNet50 are also updated now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4096065-8e49-44d0-bec7-0802cadf56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Load pre-trained ResNet50 model without top classification layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Add custom classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the pre-trained ResNet50 model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "datagen.fit(train_images)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(train_images, train_labels, batch_size=32), \n",
    "                    steps_per_epoch=len(train_images) / 32, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))\n",
    "\n",
    "# Plot the accuracy over epochs\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8cc73b-c1e5-41b4-a996-bcd9593aa409",
   "metadata": {},
   "source": [
    "### D. Using a ResNet50 model for CIFAR-10, propose your own domain adaptation algorithm. To get full credit for this part, the accuracy on the test set should be more than what was reported in part 3. You may build upon part(3) to propose your own algorithm. Explain why your proposed algorithm is working better. You may use any training data as long as it involves using other datasets (on which youâ€™ll adapt CIFAR-10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e9f64-edca-4a8e-aa5f-4e120d42b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fine-tuning a ResNet50 model on CIFAR-10 and proposing a domain adaptation algorithm to improve test set accuracy is a\n",
    "complex task. To tackle this, I'll outline a general approach that combines fine-tuning with domain adaptation techniques.\n",
    "Keep in mind that achieving better performance than a baseline ResNet50 on CIFAR-10 with domain adaptation requires careful\n",
    "experimentation and a deep understanding of domain adaptation techniques. Here's a step-by-step guide:\n",
    "\n",
    "1.Fine-tuning ResNet50 on CIFAR-10:\n",
    "\n",
    "        a. Load the pre-trained ResNet50 model without the top classification layer.\n",
    "        b. Add two fully connected (dense) layers with ReLU activation between them. The number of units in these layers\n",
    "        can be chosen based on experimentation.\n",
    "        c. Add a Softmax layer with the number of units equal to the number of classes in CIFAR-10 (10).\n",
    "        d. Compile the model using an appropriate optimizer (e.g., Adam) and loss function (e.g., categorical cross-entropy).\n",
    "        e. Perform fine-tuning by training the model on the CIFAR-10 training set. You can experiment with different\n",
    "        learning rates and batch sizes.\n",
    "\n",
    "2.Domain Adaptation:\n",
    "\n",
    "    Domain adaptation aims to improve model performance by leveraging information from other datasets. You can adapt the\n",
    "    model to CIFAR-10 by using techniques like Transfer Learning or Domain-Adversarial Training. Here's a simplified approach:\n",
    "\n",
    "        a. Collect additional datasets related to CIFAR-10 that share some characteristics but may have differences in\n",
    "        domain. For example, you could use other image datasets with similar object categories but varying in image style,\n",
    "        size, or background.\n",
    "\n",
    "        b. Fine-tune the ResNet50 model on these additional datasets, just like you did for CIFAR-10. The idea is to make\n",
    "        the model more robust to the domain shifts.\n",
    "\n",
    "        c. Combine the models fine-tuned on CIFAR-10 and the additional datasets. You can experiment with various fusion\n",
    "        techniques like model stacking, feature concatenation, or using an attention mechanism to weight the contributions\n",
    "        of the models.\n",
    "\n",
    "        d. Train the combined model with an adaptation mechanism that helps the model learn to align features across \n",
    "        different domains. One approach is to add a domain classifier that encourages domain-invariant representations,\n",
    "        similar to Domain-Adversarial Training.\n",
    "\n",
    "3.Evaluation:\n",
    "\n",
    "        a. Calculate the classification accuracy on the train set and test set for the adapted model. Ensure that you keep \n",
    "        track of accuracy over epochs during training.\n",
    "\n",
    "        b. Compare the test set accuracy of the adapted model to the baseline ResNet50 model's accuracy on CIFAR-10 (part 3).\n",
    "\n",
    "4.Explanation:\n",
    "\n",
    "    To explain why your proposed domain adaptation algorithm works better, you can emphasize the following points:\n",
    "\n",
    "        a. Domain Alignment: The adaptation technique helps align the feature representations of CIFAR-10 with those of the\n",
    "        other datasets, making the model more robust to domain shifts.\n",
    "\n",
    "        b. Transfer of Knowledge: By fine-tuning on additional datasets, the model can leverage the knowledge acquired from\n",
    "        different sources, improving its generalization ability.\n",
    "\n",
    "        c. Improved Robustness: The domain-adapted model can handle variations in data distribution, which is essential for\n",
    "        better performance on the test set.\n",
    "\n",
    "Remember that domain adaptation is a complex and nuanced field, and the success of your proposed algorithm will depend on\n",
    "the choice of additional datasets, adaptation techniques, and hyperparameter tuning. Extensive experimentation is necessary \n",
    "to achieve significant improvements in accuracy on the CIFAR-10 test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97e53e-f845-4d23-ae31-77b3fe94ff56",
   "metadata": {},
   "source": [
    "## 3: Implement a gan from scratch using Keras to generate celebrity faces from noise using this data-: https://www.kaggle.com/datasets/jessicali9530/celeba-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2987b8cd-5699-42c8-8604-e0f6f4e2876a",
   "metadata": {},
   "source": [
    "### Use cases found for GAN\n",
    "### ~ Super-resolution: increasing the resolution of input image%\n",
    "### ~ Colorise blank and white image%\n",
    "### ~ image inpainting - fill missing blocks in image%\n",
    "### ~ Anime face generatio\n",
    "### ~ font generatio\n",
    "### ~ style transfe\n",
    "### ~ human face generatio\n",
    "### ~ image to emoj'\n",
    "### ~ GAN for data augmentatio\n",
    "### ~ Face ageing GA\n",
    "### ~ front facial view generation from images provided of different side%\n",
    "### ~ Photo blending- blending 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13142fb-1896-4a72-b20f-f91c86cc4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Implementing a GAN (Generative Adversarial Network) from scratch using Keras to generate celebrity faces from noise requires\n",
    "several steps. Here's a high-level overview of the process, and you can adapt it to generate other types of images as well:\n",
    "\n",
    "1.Data Preprocessing:\n",
    "\n",
    "    ~Download the CelebA dataset from Kaggle and extract the images.\n",
    "    ~Crop or resize the images to a consistent size, for example, 64x64 pixels.\n",
    "    ~Normalize the pixel values to the range [-1, 1].\n",
    "    \n",
    "2.Generator Model:\n",
    "\n",
    "    ~Create the generator model, which takes random noise as input and produces fake images.\n",
    "    ~Start with a dense layer followed by a reshape layer to form an initial feature map.\n",
    "    ~Add several upsampling layers (Conv2DTranspose) to gradually increase the spatial resolution.\n",
    "    ~Use activation functions like LeakyReLU and Batch Normalization for each layer.\n",
    "    ~The output layer should have a tanh activation function to ensure pixel values are in the range [-1, 1].\n",
    "    \n",
    "3.Discriminator Model:\n",
    "\n",
    "    ~Create the discriminator model, which takes real and fake images as input and predicts whether they are real or fake.\n",
    "    ~Use Conv2D layers to downsample the input image while increasing the number of channels.\n",
    "    ~Add activation functions like LeakyReLU and Batch Normalization.\n",
    "    ~The output layer should have a sigmoid activation function to produce a binary classification result.\n",
    "    \n",
    "4.GAN Model:\n",
    "\n",
    "    ~Combine the generator and discriminator into a GAN model.\n",
    "    ~The generator is trained within the GAN model to generate more realistic images, while the discriminator is trained\n",
    "    to distinguish real from fake.\n",
    "    \n",
    "5.Training:\n",
    "\n",
    "    ~Train the GAN in a loop. In each iteration:\n",
    "        ~Generate random noise samples.\n",
    "        ~Generate fake images using the generator.\n",
    "        ~Train the discriminator with a batch of real images and a batch of fake images, updating its weights.\n",
    "        ~Freeze the discriminator's weights during the generator update.\n",
    "        ~Train the GAN by feeding random noise through the generator and trying to trick the discriminator into classifying\n",
    "        the generated images as real.\n",
    "        \n",
    "6.Use Cases:\n",
    "\n",
    "    ~Super-Resolution: You can adapt the GAN to generate high-resolution images from low-resolution input.\n",
    "    ~Image Colorization: Modify the GAN to add color to grayscale images.\n",
    "    ~Image Inpainting: Extend the GAN to fill missing parts of images.\n",
    "    ~Anime Face Generation: Train the GAN on an anime face dataset.\n",
    "    ~Font Generation: Use GAN for generating custom fonts.\n",
    "    ~Style Transfer: Explore style transfer by integrating style loss into the GAN loss function.\n",
    "    ~Human Face Generation: Already covered in the CelebA use case.\n",
    "    ~Image to Emoji: Train a GAN to generate emoji-style images.\n",
    "    ~Data Augmentation: Augment existing datasets using GAN-generated samples.\n",
    "    ~Face Aging GAN: Train a GAN to simulate the aging of faces.\n",
    "    ~Front Facial View Generation: Use frontalization techniques with the GAN.\n",
    "    ~Photo Blending: Investigate techniques like Poisson blending for image compositing.\n",
    "    \n",
    "Remember that GAN training can be challenging, and you may need to experiment with hyperparameters, network architectures, \n",
    "and loss functions to achieve desirable results for your specific use case. Additionally, it's important to have a large \n",
    "and diverse dataset for each specific use case to ensure high-quality results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
